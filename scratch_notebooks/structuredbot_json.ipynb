{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "import llamabot as lmb\n",
    "import litellm\n",
    "\n",
    "litellm.enable_json_schema_validation = True\n",
    "litellm.drop_params = True\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "bot = lmb.StructuredBot(\n",
    "    system_prompt=\"You are a helpful assistant. Please respond with a JSON object containing a name and age.\",\n",
    "    pydantic_model=MyModel,\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "bot(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with different models for which I have API keys.\n",
    "\n",
    "model_names = [\n",
    "    \"gpt-4\",\n",
    "    \"gpt-4o\",\n",
    "    \"anthropic/claude-3-5-sonnet-20240620\",\n",
    "    \"gemini/gemini-1.5-pro-latest\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with lmb.Experiment(\"structuredbot_various_models\") as exp:\n",
    "#     for model in model_names:\n",
    "#         print()\n",
    "#         print(\"--------------------------------\")\n",
    "#         print(\"Running model: \", model)\n",
    "#         bot = lmb.StructuredBot(\n",
    "#             system_prompt=\"You are a helpful assistant. Please respond with a JSON object containing a name and age.\",\n",
    "#             pydantic_model=MyModel,\n",
    "#             model_name=model,\n",
    "#         )\n",
    "\n",
    "#         try:\n",
    "#             bot(\"What is your name?\")\n",
    "#         except Exception as e:\n",
    "#             print(\"Could not run model: \", model)\n",
    "#             print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import get_supported_openai_params\n",
    "from litellm import supports_response_schema\n",
    "\n",
    "\n",
    "for model in model_names:\n",
    "    params = get_supported_openai_params(model=model)\n",
    "    print(model, \"response_format\" in params, supports_response_schema(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llamabot as lmb\n",
    "\n",
    "bot = lmb.StructuredBot(\n",
    "    system_prompt=\"You are a helpful assistant. Please respond with a JSON object containing a name and age.\",\n",
    "    pydantic_model=MyModel,\n",
    "    model_name=\"gpt-4\",\n",
    ")\n",
    "\n",
    "bot(\"What is your name?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
